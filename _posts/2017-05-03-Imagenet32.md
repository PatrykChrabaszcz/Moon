---
published: false
---
---
published: false
---
---
layout: post
title: "Imagenet32"
date: 2017-05-03
excerpt: "Alternative to CIFAR"
tags: [imagenet, dataset, computer vision]
comments: true
---

# Imagenet32 Dataset

## General information
Imagenet32 dataset is a downsampled version of original [Imagenet](http://image-net.org/)
dataset.  
It contains 1281167 training images from 1000 categories, and 50000 validation images, 50 for each category.

To downsaple images we use algorithm **box** from python [Pillow](https://pillow.readthedocs.io/en/4.1.x/) library.

Link to [dataset](https://figshare.com/articles/Imagenet_32/4960082) (3.81Gb)

File format was inspired by [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html) dataset.  
You would need Python3 to unpickle files (It's default encoding differs from Python 2)

```ruby
require 'redcarpet'
markdown = Redcarpet.new("Hello World!")
puts markdown.to_html
```

```python
# Note that this will work with Python3
def unpickle(file):
    with open(file, 'rb') as fo:
        dict = pickle.load(fo)
    return dict
```

There are 10 files with training data ("file train\_data\_batch\_#"). Each of them contains python dictionary with fields:

* **'data'** - numpy array with uint8 numbers of shape **samples x 3072**. First 1024 numbers represent red channel, next 1024 numbers green channel, last 1024 numbers represent blue channel. See [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html) website.
* **'labels'**- number representing image class, indexing starts at 1 and it uses mapping from **map_clsloc.txt** file provided in original Imagenet devkit
* **'mean'** - mean image computed over all training samples, included for convenience, usually first preprocessing step
removes mean from all images 


## How dataset was prepared

1. Download imagenet dataset
2. Use [image_resizer_imagenet.py](https://github.com/) to resize images. 
``` bash
python image_resizer_imagent.py -i ~/images/ILSVRC2015/Data/CLS-LOC/train -o ~/data/ -s 32 -a box -r -j 10 
```

Training images were randomly shuffled and divided into 10 parts. Each "file train_data_batch_#" contains
python dictionary with fileds:
'data' - numpy array with uint8 numbers of shape [samples, 3072], first 1024 numbers represent red channels,
next 1024 numbers green channel, last 1024 numbers represent blue channel. See CIFAR website
'labels'- number representing image class, indexing starts at 1 and it uses mapping from map_clsloc.txt file
provided in original Imagenet devkit

'mean' - mean image computed over all training samples, included for convenience, usually first preprocessing step
removes mean from all images 

All validation images are stored inside 'val_data' file. It contains python dictionary with fields: 'data' and 'labels'

To read one of the files and use it in lasagne framework (NCHW format) you would use:




def load_databatch(data_folder, idx, img_size='32x32'):
    data_file = os.path.join(data_folder, 'train_data_batch_')

    d = unpickle(data_file + str(idx))
    x = d['data']
    y = d['labels']
    mean_image = d['mean']

    x = x/np.float32(255)
    mean_image = mean_image/np.float32(255)

    # Labels are indexed from 1, shift it so that indexes start at 0
    y = [i-1 for i in y]
    data_size = x.shape[0]

    x -= mean_image
    if img_size == '32x32':
        x = np.dstack((x[:, :1024], x[:, 1024:2048], x[:, 2048:]))
        x = x.reshape((x.shape[0], 32, 32, 3)).transpose(0, 3, 1, 2)
    elif img_size == '64x64':
        x = np.dstack((x[:, :4096], x[:, 4096:8192], x[:, 8192:]))
        x = x.reshape((x.shape[0], 64, 64, 3)).transpose(0, 3, 1, 2)
    else:
        raise NotImplementedError

    # create mirrored images (optional)
    X_train = x[0:data_size, :, :, :]
    Y_train = y[0:data_size]
    X_train_flip = X_train[:, :, :, ::-1]
    Y_train_flip = Y_train
    X_train = np.concatenate((X_train, X_train_flip), axis=0)
    Y_train = np.concatenate((Y_train, Y_train_flip), axis=0)

    return dict(
        X_train=lasagne.utils.floatX(X_train),
        Y_train=Y_train.astype('int32'),
        mean=mean_image)


Link to paper:
TO DO
